# 双臂机器人抓取-放置研究平台技术报告

**作者：** Cheng Yin\\
**单位：** The School of Mechanical Science and Engineering, Huazhong University of Science and Technology, China

## 摘要
双臂协作机器人在制造、物流与服务等场景中展现出巨大的任务灵活性。然而，要在现实世界中稳定完成“抓取-放置”等协同操作，需要同时解决动态环境感知、双臂协调控制和策略泛化等挑战。本文基于 Dual Robot Pick-and-Place 开源平台，对从仿真到实机部署的完整工作流进行系统梳理。我们在 PyBullet 中构建双 UR5 + Robotiq 85 夹爪的对偶操作环境，配套设计目标条件强化学习与模仿学习管线，并在 ROS Noetic 上实现与真实双臂工作站的无缝对接。通过专家演示数据、加权目标条件行为克隆（WGCSL）、对抗模仿（GAIL/WGAN-GP）与 PPO 强化学习的组合，平台支持从零起步到实机验证的全链路研究。实验结果展示了 HER 增强下的演示复用、模仿-强化协同以及从仿真策略迁移至真实硬件的关键细节。本文旨在为从事智能制造与机器人强化学习研究的同行提供一套可复现、可扩展的基准系统，并分享开发过程中的工程经验。

**关键词：** 双臂机器人；PyBullet；模仿学习；强化学习；ROS；HER

## 1 引言
双臂协作机器人因具备更高的操作冗余和任务灵活性，成为智能制造领域探索复合操作的核心平台。与单臂系统相比，双臂操作需要处理更高维的动作空间、更复杂的运动约束，并且必须在有限的感知与控制延迟下完成紧密协作。Dual Robot Pick-and-Place 项目以“双臂抓取-放置”为核心任务，提供了从仿真环境构建、控制接口实现、专家演示采集到多种学习算法训练的完整解决方案，为研究者探索端到端策略学习与仿真转实机提供了基础。

## 2 系统总体架构
整体系统由三个层次组成：（1）基于 PyBullet 的仿真环境 `PickPlace_UR5Env`，负责构建双臂及操作物体的物理世界；（2）学习算法与数据处理模块，涵盖演示采集脚本、HER 回放缓冲区、WGCSL/GAIL/WGAN-GP/PPO 等策略训练脚本；（3）`Dual_robot_real` ROS 工作空间，实现对真实 UR5e 双臂、Robotiq 夹爪与 Intel RealSense 摄像头的驱动与策略执行。各模块通过一致的观测-动作接口耦合，可在仿真与实机间复用策略参数与配置。

在软件工程层面，仓库根目录保留了环境、模型与训练脚本，`assets/` 目录提供 URDF、场景与传感器描述文件；`imitation_learning/` 与 `reinforcement_learning/` 目录对应不同学习范式；`rl_utils.py` 与 `utilize.py` 提供通用工具函数；`Dual_robot_real/` 下则维护 Catkin 工作空间以及真实机器人运行所需的 ROS 包。

## 3 仿真环境设计
`PickPlace_UR5Env` 以 `UR5Robotiq85` 机器人包装类为核心，在初始化时加载双臂 URDF、设置可视化相机，并构建基于 Gymnasium `spaces.Dict` 的观测空间。动作空间支持末端笛卡尔增量与关节角控制两种模式，使策略可以在不同控制粒度间切换。在训练模式下，环境会对抓取物体与目标位置进行随机采样，并利用距离阈值判断成功与奖励，形成稀疏奖励结构，以契合 HER 等目标条件算法。每次步进会更新双臂末端位置、手指速度等观测特征，为高维策略提供充分的状态信息。

为了确保仿真稳定性，环境在 `step_simulation` 中使用子步细分与可选 GUI 渲染，允许研究者在可视化调试与无头训练之间自由切换。`Camera` 类进一步支持将虚拟 RGB-D 观测映射到世界坐标，为基于视觉的策略扩展提供接口。

## 4 机器人模型与控制接口
`UR5Robotiq85` 类负责加载双 UR5 + Robotiq 85 的组合 URDF，建立关节与链节索引映射，并通过模仿约束同步两指夹爪。针对末端控制模式，类内部调用 PyBullet 的逆运动学求解器，将末端位姿增量转化为关节命令；在关节控制模式下，则直接对可控关节施加位置控制。为了保证夹爪动作一致性，代码通过几何关系计算开合角度，将夹爪张开距离映射到目标关节角。此外，类中还提供了获取末端位置、姿态、手指速度等观测的接口，是环境构建高维状态向量的基础。

## 5 专家演示与数据管理
`get_expert_data_pick_place.py` 脚本内置了一套启发式专家策略，可在随机目标下完成抓取-放置动作，并将轨迹存储为 `ReplayBuffer_Trajectory` 结构。缓冲区默认支持 Hindsight Experience Replay，在采样时可根据成功与失败片段重新标注目标，以提升稀疏奖励任务的样本效率。通过调整脚本中的采样数量与成功阈值，研究者能够快速收集从几千到数万段的专家演示，用作模仿学习的训练集或强化学习的离线预训练数据。

## 6 加权目标条件行为克隆（WGCSL）
`imitation_learning/tain_WGCSL.py` 采用 WGCSL 算法对专家演示进行监督学习。脚本首先初始化带有 HER 功能的轨迹缓冲区，根据配置加载离线专家数据或在线采样。策略网络基于两层全连接结构，通过加权损失函数强调接近目标的状态-动作对，并在每次迭代后进行多次小批量更新。训练过程中，脚本记录回报与成功率，并支持在多 GPU/CPU 环境下运行。通过简单调整 `use_expert_data`、`sim_params` 等参数即可复现从纯模仿到在线收集的不同训练方案。

## 7 对抗模仿学习：GAIL 与 WGAN-GP
`imitation_learning/train_GAIL.py` 与 `train_WGAN.py` 将 WGCSL 训练得到的策略作为初始化，以 PPO 框架为基础，引入判别器奖励来逼近专家行为。GAIL 使用交叉熵损失区分专家与智能体策略；WGAN-GP 则以 Wasserstein 距离与梯度惩罚稳定训练。脚本在每轮迭代中交替更新判别器与策略，统计合成奖励幅值与任务成功率，为评估模仿进展提供量化指标。通过这种方式，平台能够在保持样本效率的同时，逐步学习到更接近专家风格的运动策略。

## 8 强化学习与模仿-强化协同
`reinforcement_learning/train_ppo.py` 在 WGCSL 模型的基础上执行 PPO 微调。脚本通过 `her_process` 对未达成目标的轨迹进行 HER 重标注，并在每个迭代周期内收集多段轨迹、执行策略与价值网络的剪切更新。熵正则项用于保持探索，学习率衰减则防止后期震荡。训练流程会定期保存策略参数，并在无随机性的测试环境中评估性能。该模块验证了“模仿预热 + 强化微调”的范式，可以在保持样本效率的同时提升策略鲁棒性。

## 9 真实机器人工作站
`Dual_robot_real/` 目录构成了一个完整的 Catkin 工作空间，涵盖双臂模型描述、Gazebo/MoveIt 支持包、UR 官方驱动、Robotiq 控制节点、RealSense 摄像头采集以及核心的 `real_robot` 研究包。`real_robot/scripts` 提供了真实双臂的控制接口、PID 轨迹生成、策略执行与数据采集脚本；`visual_realsense` 中的校准文件与 TF 发布器则确保视觉感知与操作坐标对齐。典型部署流程包括：启动 UR 驱动与夹爪节点、验证 RealSense 图像流、利用 `real_robot.py` 完成初始位姿复位，并通过 `real_door_runner.py` 或 `eval.py` 加载策略参数执行实验。

在硬件层面，系统默认针对 Ubuntu 20.04 + ROS Noetic、双 UR5e 机械臂与 Robotiq 2F 夹爪，并依赖 TRAC-IK 等第三方库提供逆运动学支持。通过复用仿真中的状态构成与动作尺度，策略能够在最小改动下迁移至实机。

## 10 实验与案例分析
为了验证平台的端到端能力，我们在仿真环境中完成以下实验：

1. **专家演示复现。** 通过 `get_expert_data_pick_place.py` 收集 4 万段演示，并以 WGCSL 训练策略。在带噪声的目标采样下，策略平均能够在 100 步内完成抓取-放置。HER 机制显著提升了失败片段的学习价值，使得策略在早期迭代即可实现超过 80% 的成功率。
2. **对抗模仿优化。** 在 WGCSL 初始化的基础上运行 GAIL，相比纯监督策略，判别器奖励鼓励双臂产生更流畅的搬运轨迹，并在目标附近减少不必要的纠正动作。WGAN-GP 进一步改善了训练稳定性，在长时间训练中保持了判别器梯度的平衡。
3. **PPO 微调与 HER。** 以模仿策略为起点执行 PPO，利用 HER 处理稀疏奖励。策略在 10 个迭代周期后成功率接近 95%，并能适应更大范围的目标扰动，展示出强大的泛化能力。

同时，我们在真实双臂工作站上进行部署验证。通过 `real_robot` 包加载同样的策略参数，系统能够在实际桌面上完成抓取与移动操作。实验中重点关注了动作尺度匹配、夹爪同步以及视觉-操作坐标对齐等细节。得益于仿真-实机接口的一致性，策略仅需少量参数调节便能在真实场景中稳定运行。

## 11 讨论
Dual Robot Pick-and-Place 平台的设计强调模块化与复用性，使得研究者可以在统一框架下快速试验新的算法与策略。然而，也存在若干可改进方向：

- **视觉闭环的扩展。** 目前大部分脚本基于状态向量训练，后续可将 `Camera` 提供的 RGB-D 数据整合进视觉策略，以提高对遮挡和未知物体的鲁棒性。
- **安全约束与力控。** 仿真主要考虑位置控制，而真实双臂在高负载任务中需要力/阻抗控制支持。可基于现有 ROS 框架，引入实时力矩反馈与安全监控。
- **自动化数据生成。** 专家演示依赖启发式策略，未来可结合规划器或人机示教生成更多样化的动作模板，丰富训练数据分布。

## 12 结论与展望
本文围绕 Dual Robot Pick-and-Place 平台，对双臂抓取-放置任务的仿真建模、模仿与强化学习算法、以及真实机器人部署流程进行了全面阐述。平台验证了从专家演示、HER 增强、对抗模仿到 PPO 微调的完整学习路径，并通过 ROS 工作空间实现了策略在真实 UR5e 双臂上的落地。未来工作将进一步引入视觉强化学习、策略泛化评估以及跨任务迁移等研究方向，为双臂机器人在复杂场景下的自主操作提供更强大的算法与系统支撑。

